{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook builds Direct Preference Optimization (DPO) from the ground up and applies it to a large language model (LLM) to improve how well its responses reflect user preferences."
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "K2pmHZSa_Qyg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loading a Preference Datasaet**"
      ],
      "metadata": {
        "id": "_EBzmP-M_Qyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import urllib\n",
        "\n",
        "\n",
        "def download_and_load_file(file_path, url):\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            text_data = response.read().decode(\"utf-8\")\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(text_data)\n",
        "    else:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            text_data = file.read()\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "file_path = \"instruction-data-with-preference.json\"\n",
        "url = \"https://raw.githubusercontent.com/abdussahid26/LLM-Post-training-Techniques/main/instruction-data-with-preference.json\"\n",
        "\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(f\"Number of entries: {len(data)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:26.425637Z",
          "iopub.execute_input": "2025-05-30T09:26:26.425929Z",
          "iopub.status.idle": "2025-05-30T09:26:26.444682Z",
          "shell.execute_reply.started": "2025-05-30T09:26:26.425906Z",
          "shell.execute_reply": "2025-05-30T09:26:26.443181Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXHAx-oD_Qyi",
        "outputId": "590de001-5da5-4c5e-99da-c077f28fbd1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries: 1100\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "\n",
        "pprint.pp(data[0])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:26.446088Z",
          "iopub.execute_input": "2025-05-30T09:26:26.446866Z",
          "iopub.status.idle": "2025-05-30T09:26:26.467211Z",
          "shell.execute_reply.started": "2025-05-30T09:26:26.446837Z",
          "shell.execute_reply": "2025-05-30T09:26:26.466181Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nh7a8nn_Qyk",
        "outputId": "f4bceb06-d5a7-4183-a0c7-9fd3f6130857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'Evaluate the following phrase by transforming it into the '\n",
            "                'spelling given.',\n",
            " 'input': 'freind --> friend',\n",
            " 'output': 'The spelling of the given phrase \"freind\" is incorrect, the '\n",
            "           'correct spelling is \"friend\".',\n",
            " 'rejected': 'The spelling of the given phrase \"freind\" is flat out wrong, get '\n",
            "             'it together, the correct spelling is \"friend\".',\n",
            " 'chosen': 'The spelling of the given phrase \"freind\" is incorrect, the '\n",
            "           'correct spelling is \"friend\".'}\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pp(data[1])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:26.468141Z",
          "iopub.execute_input": "2025-05-30T09:26:26.468459Z",
          "iopub.status.idle": "2025-05-30T09:26:26.486788Z",
          "shell.execute_reply.started": "2025-05-30T09:26:26.468430Z",
          "shell.execute_reply": "2025-05-30T09:26:26.485697Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLvzAjE6_Qyk",
        "outputId": "d6000a5b-b33e-4c3e-a907-6eb19b3a675a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'Edit the following sentence for grammar.',\n",
            " 'input': 'He go to the park every day.',\n",
            " 'output': 'He goes to the park every day.',\n",
            " 'rejected': 'He goes to the stupid park every single day.',\n",
            " 'chosen': 'He goes to the park every day.'}\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Overview\n",
        "\n",
        "The dataset consists of **5 keys**:\n",
        "\n",
        "1. **`instruction`** and **`input`**:  \n",
        "   These are used as inputs to the LLM.\n",
        "\n",
        "2. **`output`**:  \n",
        "   This contains the response that the model was trained on during the [`Supervised Instruction Fine-tuning`](https://github.com/abdussahid26/LLM-Post-training-Techniques/blob/main/Supervised_Instruction_Fine_tuning.ipynb) phase.\n",
        "\n",
        "3. **`chosen`** and **`rejected`**:  \n",
        "   These are used for **DPO**.  \n",
        "   - `chosen` is the **preferred** response.  \n",
        "   - `rejected` is the **dispreferred** response.\n",
        "\n",
        "---\n",
        "\n",
        "### Objective\n",
        "\n",
        "The goal is to fine-tune the model to **prefer the style and content of the `chosen` responses** over the `rejected` ones.\n"
      ],
      "metadata": {
        "id": "EBrpTedP_Qyl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's format the model input by applying the **Alpaca** prompt style.\n",
        "\n",
        "## **Alpaca prompt style template:**\n",
        "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "\n",
        "**\\### Instruction:** <br>Identify the correct spelling of the following word.\n",
        "\n",
        "**\\### Input:** <br>Ocassion\n",
        "\n",
        "**\\### Response:** <br>The correct spelling is 'Occasion'."
      ],
      "metadata": {
        "id": "ObnbL6e__Qyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_input(entry):\n",
        "    instruction_text=(\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "    input_text=f\"\\n\\n### Input:\\n{entry['input']}\" if entry['input'] else \"\"\n",
        "\n",
        "    return instruction_text + input_text"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:26.489789Z",
          "iopub.execute_input": "2025-05-30T09:26:26.490636Z",
          "iopub.status.idle": "2025-05-30T09:26:26.508228Z",
          "shell.execute_reply.started": "2025-05-30T09:26:26.490586Z",
          "shell.execute_reply": "2025-05-30T09:26:26.507006Z"
        },
        "id": "uknNev9F_Qyl"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = format_input(data[0])\n",
        "print(model_input)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:26.509304Z",
          "iopub.execute_input": "2025-05-30T09:26:26.509642Z",
          "iopub.status.idle": "2025-05-30T09:26:26.527718Z",
          "shell.execute_reply.started": "2025-05-30T09:26:26.509614Z",
          "shell.execute_reply": "2025-05-30T09:26:26.526582Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbpLZCUa_Qym",
        "outputId": "5a1b9d4a-fd7a-40a5-d22b-c28b61f2d766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Evaluate the following phrase by transforming it into the spelling given.\n",
            "\n",
            "### Input:\n",
            "freind --> friend\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, we can format the chosen and rejected responses using the **Alpaca prompt style**."
      ],
      "metadata": {
        "id": "byId_Ejm_Qym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "desired_response=f\"### Response: \\n{data[0]['chosen']}\"\n",
        "print(desired_response)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:26.528633Z",
          "iopub.execute_input": "2025-05-30T09:26:26.529170Z",
          "iopub.status.idle": "2025-05-30T09:26:26.546333Z",
          "shell.execute_reply.started": "2025-05-30T09:26:26.529140Z",
          "shell.execute_reply": "2025-05-30T09:26:26.545328Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7kzlQgh_Qym",
        "outputId": "e5885af4-458a-4459-c0ba-8bd2c4a5ff92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Response: \n",
            "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "possible_response=f\"### Response:\\n{data[0]['rejected']}\"\n",
        "print(possible_response)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:26.547424Z",
          "iopub.execute_input": "2025-05-30T09:26:26.547840Z",
          "iopub.status.idle": "2025-05-30T09:26:26.565234Z",
          "shell.execute_reply.started": "2025-05-30T09:26:26.547810Z",
          "shell.execute_reply": "2025-05-30T09:26:26.564275Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yF5BvM-_Qyn",
        "outputId": "2f8d968d-1c4b-4e84-94c3-8dd08958fea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Response:\n",
            "The spelling of the given phrase \"freind\" is flat out wrong, get it together, the correct spelling is \"friend\".\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Training, Validation, & Testsplit"
      ],
      "metadata": {
        "id": "piG7IJny_Qyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_portion=int(0.85 * len(data)) # 85% for training\n",
        "test_portion=int(0.1 * len(data)) # 10% for testing\n",
        "val_portion=len(data) - train_portion - test_portion # Remaining 5% for validation\n",
        "\n",
        "train_data = data[: train_portion]\n",
        "test_data = data[train_portion : train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion :]\n",
        "\n",
        "print(f\"Training set length: {len(train_data)}\")\n",
        "print(f\"Test set length: {len(test_data)}\")\n",
        "print(f\"Validation set length: {len(val_data)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:26.566175Z",
          "iopub.execute_input": "2025-05-30T09:26:26.566459Z",
          "iopub.status.idle": "2025-05-30T09:26:26.584517Z",
          "shell.execute_reply.started": "2025-05-30T09:26:26.566438Z",
          "shell.execute_reply": "2025-05-30T09:26:26.583571Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeE2ID3y_Qyn",
        "outputId": "b08c1379-12da-4871-c37c-1a53601c2611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set length: 935\n",
            "Test set length: 110\n",
            "Validation set length: 55\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a `PerformanceDataset` Class and Batch Processing Function"
      ],
      "metadata": {
        "id": "VQh_mMUm_Qyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class PreferenceDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data=data\n",
        "        self.encoded_texts=[]\n",
        "        for entry in data:\n",
        "            prompt=format_input(entry)\n",
        "            chosen_response=entry['chosen']\n",
        "            rejected_response=entry['rejected']\n",
        "\n",
        "            prompt_tokens=tokenizer.encode(prompt)\n",
        "            chosen_full_text=f\"{prompt}\\n\\n### Response:\\n{chosen_response}\"\n",
        "            rejected_full_text=f\"{prompt}\\n\\n### Response:\\n{rejected_response}\"\n",
        "            chosen_full_tokens=tokenizer.encode(chosen_full_text)\n",
        "            rejected_full_tokens=tokenizer.encode(rejected_full_text)\n",
        "\n",
        "            self.encoded_texts.append({\n",
        "                \"prompt\": prompt_tokens,\n",
        "                \"chosen\": chosen_full_tokens,\n",
        "                \"rejected\": rejected_full_tokens,\n",
        "            })\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:26.586644Z",
          "iopub.execute_input": "2025-05-30T09:26:26.586909Z",
          "iopub.status.idle": "2025-05-30T09:26:28.616620Z",
          "shell.execute_reply.started": "2025-05-30T09:26:26.586889Z",
          "shell.execute_reply": "2025-05-30T09:26:28.615737Z"
        },
        "id": "wSsQgw0V_Qyn"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:28.618106Z",
          "iopub.execute_input": "2025-05-30T09:26:28.618875Z",
          "iopub.status.idle": "2025-05-30T09:26:32.332215Z",
          "shell.execute_reply.started": "2025-05-30T09:26:28.618852Z",
          "shell.execute_reply": "2025-05-30T09:26:32.330712Z"
        },
        "id": "YuWIph7d_Qyo"
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
        "train_dataset=PreferenceDataset(train_data, tokenizer)\n",
        "\n",
        "print(f\"length of tokenize data[20]: {len(train_dataset[20])}\") # prompt, chosen, response\n",
        "print(f\"length of tokenize data[21]: {len(train_dataset[21])}\")\n",
        "print(f\"length of tokenize data[22]: {len(train_dataset[22])}\")\n",
        "print(f\"length of tokenize data[23]: {len(train_dataset[23])}\")\n",
        "print(f\"length of tokenize data[24]: {len(train_dataset[24])}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:32.333623Z",
          "iopub.execute_input": "2025-05-30T09:26:32.333973Z",
          "iopub.status.idle": "2025-05-30T09:26:32.741566Z",
          "shell.execute_reply.started": "2025-05-30T09:26:32.333940Z",
          "shell.execute_reply": "2025-05-30T09:26:32.740653Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WdpuR7i_Qyo",
        "outputId": "db90d945-26ce-4083-bf18-f694619ce433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of tokenize data[20]: 3\n",
            "length of tokenize data[21]: 3\n",
            "length of tokenize data[22]: 3\n",
            "length of tokenize data[23]: 3\n",
            "length of tokenize data[24]: 3\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to accelerate training by collecting multiple training examples in a `batch`, which necessitates padding all inputs to a similar length. Instead of appending the `<|endoftext|>` tokens to the text inputs, we can append the token ID 50256. For padding purpose, we adopt a more sophisticated approach by developing a custom `collate_function` that we can pass to the `dataloader`. This custom collate function pads the training examples in each batch to the same length while allowing different batches to have different lengths. This approach minimizes unnecessary padding by only extending sequences to match the longest one in each batch, not the whole datset."
      ],
      "metadata": {
        "id": "f61gyl8O_Qyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_function(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    allowed_max_length=None,\n",
        "    mask_prompt_tokens=True,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Initialize lists to contain batch data\n",
        "    batch_data={\n",
        "        \"prompt\": [],\n",
        "        \"chosen\": [],\n",
        "        \"rejected\": [],\n",
        "        \"rejected_mask\": [],\n",
        "        \"chosen_mask\": []\n",
        "    }\n",
        "\n",
        "    # Determine the longest sequence to set a common padding length\n",
        "    max_length_common=0\n",
        "    if batch:\n",
        "        for key in [\"chosen\", \"rejected\"]:\n",
        "            current_max = max(len(item[key]) + 1 for item in batch)\n",
        "            max_length_common = max(max_length_common, current_max)\n",
        "\n",
        "    # Process each item in the batch\n",
        "    for item in batch:\n",
        "        prompt = torch.tensor(item[\"prompt\"])\n",
        "        batch_data[\"prompt\"].append(prompt)\n",
        "\n",
        "        for key in [\"chosen\", \"rejected\"]:\n",
        "            # Step 3: Adjust to the common maximum length with padding tokens (end of text token, 50256)\n",
        "            sequence = item[key]\n",
        "            padded = sequence + [pad_token_id] * (max_length_common - len(sequence))\n",
        "            mask = torch.ones(len(padded)).bool() # Create a boolean mask of the same length as padded, initialized to True\n",
        "\n",
        "            # Set mask for all padding tokens to False\n",
        "            mask[len(sequence):] = False\n",
        "\n",
        "            # Set mask for all input tokens to False\n",
        "            # +2 sets the 2 newliine (\"\\n\") tokens before \"### Response\" to False\n",
        "            if mask_prompt_tokens:\n",
        "                mask[:prompt.shape[0]+2] = False # Our aim is to optimize the response quality, not the prompt interpretation.\n",
        "                # prompt.shape[0] is the number of tokens in the prompt\n",
        "\n",
        "            batch_data[key].append(torch.tensor(padded))\n",
        "            batch_data[f\"{key}_mask\"].append(mask)\n",
        "\n",
        "    # Final processing\n",
        "    for key in [\"chosen\", \"rejected\", \"chosen_mask\", \"rejected_mask\"]:\n",
        "        # Stack all sequences into a tensor for the given key\n",
        "        tensor_stack = torch.stack(batch_data[key]) # [Batch_Size, Sequence_Length]\n",
        "\n",
        "        # Optionally truncate to maximum sequence length\n",
        "        if allowed_max_length is not None:\n",
        "            tensor_stack = tensor_stack[:, : allowed_max_length]\n",
        "\n",
        "        # Move to the specified device\n",
        "        batch_data[key] = tensor_stack.to(device)\n",
        "\n",
        "    return batch_data"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:32.743751Z",
          "iopub.execute_input": "2025-05-30T09:26:32.744010Z",
          "iopub.status.idle": "2025-05-30T09:26:32.752806Z",
          "shell.execute_reply.started": "2025-05-30T09:26:32.743990Z",
          "shell.execute_reply": "2025-05-30T09:26:32.751970Z"
        },
        "id": "J59eD5rS_Qyo"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "customized_collate = partial(\n",
        "    collate_function,\n",
        "    device = device,\n",
        "    mask_prompt_tokens = True, # Optional\n",
        "    allowed_max_length = 1024 # The supported context length of the model\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:32.753693Z",
          "iopub.execute_input": "2025-05-30T09:26:32.753991Z",
          "iopub.status.idle": "2025-05-30T09:26:32.780107Z",
          "shell.execute_reply.started": "2025-05-30T09:26:32.753970Z",
          "shell.execute_reply": "2025-05-30T09:26:32.778639Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcyvXGWe_Qyo",
        "outputId": "a6f1af8d-847e-4f7d-cc6e-d60b9d320642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's see the `customized_collate` in action and apply it to some sample data from our preference dataset; for this, we take the first two entries:"
      ],
      "metadata": {
        "id": "XbJwLIl__Qyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_data = data[:2]\n",
        "\n",
        "for i in example_data:\n",
        "    pprint.pp(i)\n",
        "    print()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:32.781224Z",
          "iopub.execute_input": "2025-05-30T09:26:32.781673Z",
          "iopub.status.idle": "2025-05-30T09:26:32.804757Z",
          "shell.execute_reply.started": "2025-05-30T09:26:32.781635Z",
          "shell.execute_reply": "2025-05-30T09:26:32.803565Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reo6cwYc_Qyp",
        "outputId": "7549125d-e8c7-4fba-ab57-e847a95df153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'Evaluate the following phrase by transforming it into the '\n",
            "                'spelling given.',\n",
            " 'input': 'freind --> friend',\n",
            " 'output': 'The spelling of the given phrase \"freind\" is incorrect, the '\n",
            "           'correct spelling is \"friend\".',\n",
            " 'rejected': 'The spelling of the given phrase \"freind\" is flat out wrong, get '\n",
            "             'it together, the correct spelling is \"friend\".',\n",
            " 'chosen': 'The spelling of the given phrase \"freind\" is incorrect, the '\n",
            "           'correct spelling is \"friend\".'}\n",
            "\n",
            "{'instruction': 'Edit the following sentence for grammar.',\n",
            " 'input': 'He go to the park every day.',\n",
            " 'output': 'He goes to the park every day.',\n",
            " 'rejected': 'He goes to the stupid park every single day.',\n",
            " 'chosen': 'He goes to the park every day.'}\n",
            "\n"
          ]
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's instantiate an `example_dataset` and use a PyTorch `DataLoader` to create an `example_dataloader` that mimics the dataloader we will se for the model training later."
      ],
      "metadata": {
        "id": "ouX-8tsV_Qyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "example_dataset = PreferenceDataset(example_data, tokenizer)\n",
        "\n",
        "example_dataloader = DataLoader(\n",
        "    example_dataset,\n",
        "    batch_size=2,\n",
        "    collate_fn=customized_collate,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:32.805689Z",
          "iopub.execute_input": "2025-05-30T09:26:32.805936Z",
          "iopub.status.idle": "2025-05-30T09:26:32.824056Z",
          "shell.execute_reply.started": "2025-05-30T09:26:32.805916Z",
          "shell.execute_reply": "2025-05-30T09:26:32.823154Z"
        },
        "id": "S-G5hhGV_Qyp"
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset has the following keys:"
      ],
      "metadata": {
        "id": "598DuWoo_Qyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in example_dataloader:\n",
        "    break\n",
        "\n",
        "print(f\"batch.keys: {batch.keys()}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:32.825083Z",
          "iopub.execute_input": "2025-05-30T09:26:32.825364Z",
          "iopub.status.idle": "2025-05-30T09:26:32.846281Z",
          "shell.execute_reply.started": "2025-05-30T09:26:32.825345Z",
          "shell.execute_reply": "2025-05-30T09:26:32.845126Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbQt1n0z_Qyq",
        "outputId": "ad25d0c6-a6ea-491f-ca33-edd4826f2629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch.keys: dict_keys(['prompt', 'chosen', 'rejected', 'rejected_mask', 'chosen_mask'])\n"
          ]
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "source": [
        "The prompts are a list of tensors, where each tensor contains the token IDs for a given example; since we selected a batch size of 2, we have two list of token ID tensors here."
      ],
      "metadata": {
        "id": "s9oMeXuj_Qyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch[\"prompt\"]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:32.847612Z",
          "iopub.execute_input": "2025-05-30T09:26:32.848043Z",
          "iopub.status.idle": "2025-05-30T09:26:32.865579Z",
          "shell.execute_reply.started": "2025-05-30T09:26:32.848020Z",
          "shell.execute_reply": "2025-05-30T09:26:32.864501Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG3ut5Fv_Qyq",
        "outputId": "8991fcbb-a2ac-4beb-a3b2-824be48df4a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
              "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
              "         21017, 46486,    25,   198,    36,  2100,  4985,   262,  1708,  9546,\n",
              "           416, 25449,   340,   656,   262, 24993,  1813,    13,   198,   198,\n",
              "         21017, 23412,    25,   198, 19503,   521, 14610,  1545]),\n",
              " tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
              "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
              "         21017, 46486,    25,   198, 18378,   262,  1708,  6827,   329, 23491,\n",
              "            13,   198,   198, 21017, 23412,    25,   198,  1544,   467,   284,\n",
              "           262,  3952,   790,  1110,    13])]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We don't really need the responses for training; what we need to feed to the model during training are the `chosen` and `rejected` entries.\n",
        "- The `chosen` and `rejected` response entries are padded so that we can stack them as tensors; similar to the prompts, these response texts are encoded into token IDs."
      ],
      "metadata": {
        "id": "4RKzRI13_Qyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch[\"chosen\"]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:32.867968Z",
          "iopub.execute_input": "2025-05-30T09:26:32.868288Z",
          "iopub.status.idle": "2025-05-30T09:26:32.885407Z",
          "shell.execute_reply.started": "2025-05-30T09:26:32.868266Z",
          "shell.execute_reply": "2025-05-30T09:26:32.884523Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cExon_4C_Qyq",
        "outputId": "8410c743-b87c-4c31-e645-0c457c091128"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
              "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
              "         21017, 46486,    25,   198,    36,  2100,  4985,   262,  1708,  9546,\n",
              "           416, 25449,   340,   656,   262, 24993,  1813,    13,   198,   198,\n",
              "         21017, 23412,    25,   198, 19503,   521, 14610,  1545,   198,   198,\n",
              "         21017, 18261,    25,   198,   464, 24993,   286,   262,  1813,  9546,\n",
              "           366, 19503,   521,     1,   318, 11491,    11,   262,  3376, 24993,\n",
              "           318,   366,  6726,  1911, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "         50256],\n",
              "        [21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
              "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
              "         21017, 46486,    25,   198, 18378,   262,  1708,  6827,   329, 23491,\n",
              "            13,   198,   198, 21017, 23412,    25,   198,  1544,   467,   284,\n",
              "           262,  3952,   790,  1110,    13,   198,   198, 21017, 18261,    25,\n",
              "           198,  1544,  2925,   284,   262,  3952,   790,  1110,    13, 50256,\n",
              "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
              "         50256]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The token IDs above represent the model inputs, but in this format, they are hard to interpret for us humans.\n",
        "- So, let's implement a small utility function to convert them back into text so that we can inspect and interpret them more easily."
      ],
      "metadata": {
        "id": "ZjpB8DzE_Qyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_tokens_from_batch(token_ids, tokenizer):\n",
        "    ids_in_python_list = token_ids.flatten().tolist()\n",
        "    return tokenizer.decode(ids_in_python_list)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:32.886659Z",
          "iopub.execute_input": "2025-05-30T09:26:32.886998Z",
          "iopub.status.idle": "2025-05-30T09:26:32.905505Z",
          "shell.execute_reply.started": "2025-05-30T09:26:32.886971Z",
          "shell.execute_reply": "2025-05-30T09:26:32.904222Z"
        },
        "id": "N3E8V0Pb_Qyq"
      },
      "outputs": [],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's apply the `decode_tokens_from_batch` utility function to the first prompt entry in the batch."
      ],
      "metadata": {
        "id": "f114-8k9_Qyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = decode_tokens_from_batch(\n",
        "    token_ids=batch[\"prompt\"][0], # [0] for the first entry in the batch\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "print(text)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:32.906481Z",
          "iopub.execute_input": "2025-05-30T09:26:32.906777Z",
          "iopub.status.idle": "2025-05-30T09:26:32.923862Z",
          "shell.execute_reply.started": "2025-05-30T09:26:32.906757Z",
          "shell.execute_reply": "2025-05-30T09:26:32.922707Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCxhdcXl_Qyr",
        "outputId": "7c4606c9-9680-4b8e-b1a4-6f6bf8dada67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Evaluate the following phrase by transforming it into the spelling given.\n",
            "\n",
            "### Input:\n",
            "freind --> friend\n"
          ]
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": [
        "text = decode_tokens_from_batch(\n",
        "    token_ids=batch[\"chosen\"][0],\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "print(text)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:32.924800Z",
          "iopub.execute_input": "2025-05-30T09:26:32.925708Z",
          "iopub.status.idle": "2025-05-30T09:26:32.940748Z",
          "shell.execute_reply.started": "2025-05-30T09:26:32.925676Z",
          "shell.execute_reply": "2025-05-30T09:26:32.939383Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTKIJut__Qyr",
        "outputId": "46ad38c6-5513-463f-bf1b-290b97d1f8b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Evaluate the following phrase by transforming it into the spelling given.\n",
            "\n",
            "### Input:\n",
            "freind --> friend\n",
            "\n",
            "### Response:\n",
            "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n"
          ]
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": [
        "- As we can see above, similar to supervised instruction finetuning, the response that is passed to the model during training also contains the input prompt.\n",
        "- Also note that we included `<|endoftext|>` tokens as padding tokens, which are necessary so that we can extend the responses to a similar length to stack them as a batch.\n",
        "- The `<|endoftext|>` tokens will be ignored in the loss later so that they won't affect the training outcome.\n",
        "\n",
        "\n",
        "Let's also inspect the corresponding rejected response."
      ],
      "metadata": {
        "id": "VYUNC-pw_Qyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = decode_tokens_from_batch(\n",
        "    token_ids=batch[\"rejected\"][0],\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:32.941846Z",
          "iopub.execute_input": "2025-05-30T09:26:32.942210Z",
          "iopub.status.idle": "2025-05-30T09:26:32.960355Z",
          "shell.execute_reply.started": "2025-05-30T09:26:32.942158Z",
          "shell.execute_reply": "2025-05-30T09:26:32.959100Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOqX9xmS_Qyr",
        "outputId": "a5527207-d1c6-447b-8a62-9c21ccd0e535"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Evaluate the following phrase by transforming it into the spelling given.\n",
            "\n",
            "### Input:\n",
            "freind --> friend\n",
            "\n",
            "### Response:\n",
            "The spelling of the given phrase \"freind\" is flat out wrong, get it together, the correct spelling is \"friend\".<|endoftext|>\n"
          ]
        }
      ],
      "execution_count": 22
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, as we can see above, the rejected response is a more impolite version of the chosen response (we don't want the model to generate impolite responses)"
      ],
      "metadata": {
        "id": "_yhlM0ar_Qyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's talk about the data masks; if you took a closer look at our custom collate function we implemented above, we created a `chosen_mask` and a `rejected_mask` for each dataset entry. The masks have the same shape as the response entries."
      ],
      "metadata": {
        "id": "trFLWTZs_Qys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Chosen inputs: {batch['chosen'][0].shape}\")\n",
        "print(f\"Chosen mask: {batch['chosen_mask'][0].shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:26:32.961327Z",
          "iopub.execute_input": "2025-05-30T09:26:32.961640Z",
          "iopub.status.idle": "2025-05-30T09:26:32.976723Z",
          "shell.execute_reply.started": "2025-05-30T09:26:32.961616Z",
          "shell.execute_reply": "2025-05-30T09:26:32.975611Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-LUgLkC_Qys",
        "outputId": "22e1e64d-e820-42c0-aec0-374d82ed5155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen inputs: torch.Size([81])\n",
            "Chosen mask: torch.Size([81])\n"
          ]
        }
      ],
      "execution_count": 23
    },
    {
      "cell_type": "code",
      "source": [
        "batch[\"chosen_mask\"][0]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:27:01.487443Z",
          "iopub.execute_input": "2025-05-30T09:27:01.487780Z",
          "iopub.status.idle": "2025-05-30T09:27:01.495302Z",
          "shell.execute_reply.started": "2025-05-30T09:27:01.487756Z",
          "shell.execute_reply": "2025-05-30T09:27:01.493705Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52fZTkCn_Qyt",
        "outputId": "eec1cf60-71ef-402f-8bdb-32a192ed84ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True, False, False, False, False, False, False,\n",
              "        False], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The `True` values denote the token IDs that correspond to the actual response.\n",
        "- The `False` tokens correspond to token IDs that correspond to either `prompt` tokens (if we set `mask_prompt_tokens=True` in the `collate_function` function, which we previously did) or padding tokens.\n",
        "- Hence, we can use the mask as a selection mask to select only the token IDs that correspond to the response, that is, stripping all prompt and padding tokens. as we can see below."
      ],
      "metadata": {
        "id": "nYoFWgyO_Qyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = decode_tokens_from_batch(\n",
        "    token_ids=batch[\"chosen\"][0][batch[\"chosen_mask\"][0]],\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "print(text)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:32:49.650369Z",
          "iopub.execute_input": "2025-05-30T09:32:49.650698Z",
          "iopub.status.idle": "2025-05-30T09:32:49.657352Z",
          "shell.execute_reply.started": "2025-05-30T09:32:49.650675Z",
          "shell.execute_reply": "2025-05-30T09:32:49.656397Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMAuE6se_Qyt",
        "outputId": "053b5d50-0b70-495a-b727-fc279785d0d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Response:\n",
            "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"
          ]
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": [
        "text = decode_tokens_from_batch(\n",
        "    token_ids=batch[\"rejected\"][0][batch[\"rejected_mask\"][0]],\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "print(text)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:34:09.609107Z",
          "iopub.execute_input": "2025-05-30T09:34:09.609422Z",
          "iopub.status.idle": "2025-05-30T09:34:09.615367Z",
          "shell.execute_reply.started": "2025-05-30T09:34:09.609399Z",
          "shell.execute_reply": "2025-05-30T09:34:09.614436Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZORq-HI_Qyt",
        "outputId": "da89ccf5-a918-48e3-9184-f11b66a89786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Response:\n",
            "The spelling of the given phrase \"freind\" is flat out wrong, get it together, the correct spelling is \"friend\".\n"
          ]
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Training, Validation, and Testset DataLoader"
      ],
      "metadata": {
        "id": "adWE33Iw_Qyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(123)\n",
        "batch_size=8\n",
        "\n",
        "train_dataset = PreferenceDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_dataset = PreferenceDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "test_dataset = PreferenceDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=0\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:42:20.220528Z",
          "iopub.execute_input": "2025-05-30T09:42:20.221484Z",
          "iopub.status.idle": "2025-05-30T09:42:20.352503Z",
          "shell.execute_reply.started": "2025-05-30T09:42:20.221453Z",
          "shell.execute_reply": "2025-05-30T09:42:20.351632Z"
        },
        "id": "3nGvfdvj_Qyt"
      },
      "outputs": [],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's iterate through the dataloader and take a look at the dataset shapes."
      ],
      "metadata": {
        "id": "XAJmqYvE_Qyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader:\")\n",
        "for batch in train_loader:\n",
        "    print(\n",
        "        batch[\"chosen\"].shape,\n",
        "        batch[\"rejected\"].shape,\n",
        "    )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T09:44:02.925901Z",
          "iopub.execute_input": "2025-05-30T09:44:02.926226Z",
          "iopub.status.idle": "2025-05-30T09:44:03.071598Z",
          "shell.execute_reply.started": "2025-05-30T09:44:02.926202Z",
          "shell.execute_reply": "2025-05-30T09:44:03.070577Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbfRFGud_Qyu",
        "outputId": "d039248f-8df0-459c-bc8b-46e3e3d8e26a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n"
          ]
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading a Finetuned LLM for DPO Alignment\n",
        "\n",
        "- LLM alignment steps, such as RLHF or DPO, assume that we already have an `instruction-finetuned model`."
      ],
      "metadata": {
        "id": "BjI7b1Y0_Qyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "import os\n",
        "import requests\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "google_drive_path = \"/content/drive/My Drive/Supervised Instruction Fine-tuning/gpt2-medium355M-sft.pth\"  # Readers need to adjust this path\n",
        "shutil.copy(google_drive_path, \".\")\n",
        "\n",
        "\n",
        "# from pathlib import Path\n",
        "# import shutil\n",
        "\n",
        "\n",
        "# finetuned_model_path = Path(\"gpt2-medium355M-sft.pth\")\n",
        "# if not finetuned_model_path.exists():\n",
        "\n",
        "#     # Try finding the model checkpoint locally:\n",
        "#     relative_path = Path(\"..\") / \"01_main-chapter-code\" / finetuned_model_path\n",
        "#     if relative_path.exists():\n",
        "#         shutil.copy(relative_path, \".\")\n",
        "\n",
        "#     # If this notebook is run on Google Colab, get it from a Google Drive folder\n",
        "#     elif \"COLAB_GPU\" in os.environ or \"COLAB_TPU_ADDR\" in os.environ:\n",
        "#         from google.colab import drive\n",
        "#         drive.mount(\"/content/drive\")\n",
        "#         google_drive_path = \"/content/drive/My Drive/Books/LLMs-From-Scratch/ch07/colab/gpt2-medium355M-sft.pth\"  # Readers need to adjust this path\n",
        "#         shutil.copy(google_drive_path, \".\")\n",
        "\n",
        "#     else:\n",
        "#         print(\n",
        "#             f\"Could not find '{finetuned_model_path}'.\\n\"\n",
        "#             \"Run the `ch07.ipynb` notebook to finetune and save the finetuned model.\"\n",
        "#         )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T11:33:41.441777Z",
          "iopub.execute_input": "2025-05-30T11:33:41.442128Z",
          "iopub.status.idle": "2025-05-30T11:33:41.650537Z",
          "shell.execute_reply.started": "2025-05-30T11:33:41.442106Z",
          "shell.execute_reply": "2025-05-30T11:33:41.649263Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "kjIwJb-C_Qyu",
        "outputId": "54367aba-7604-4cfd-a28e-fecff2764cee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./gpt2-medium355M-sft.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "execution_count": 29
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "\n",
        "        return self.scale * norm_x + self.shift"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T11:10:08.365303Z",
          "iopub.execute_input": "2025-05-30T11:10:08.365578Z",
          "iopub.status.idle": "2025-05-30T11:10:13.973733Z",
          "shell.execute_reply.started": "2025-05-30T11:10:08.365558Z",
          "shell.execute_reply": "2025-05-30T11:10:13.972788Z"
        },
        "id": "xMPoW5EP_Qyu"
      },
      "outputs": [],
      "execution_count": 30
    },
    {
      "cell_type": "code",
      "source": [
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T11:10:24.689702Z",
          "iopub.execute_input": "2025-05-30T11:10:24.690139Z",
          "iopub.status.idle": "2025-05-30T11:10:24.696211Z",
          "shell.execute_reply.started": "2025-05-30T11:10:24.690115Z",
          "shell.execute_reply": "2025-05-30T11:10:24.695192Z"
        },
        "id": "tKNe8XgP_Qyu"
      },
      "outputs": [],
      "execution_count": 31
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T11:10:37.114458Z",
          "iopub.execute_input": "2025-05-30T11:10:37.114769Z",
          "iopub.status.idle": "2025-05-30T11:10:37.120766Z",
          "shell.execute_reply.started": "2025-05-30T11:10:37.114746Z",
          "shell.execute_reply": "2025-05-30T11:10:37.119833Z"
        },
        "id": "rPg2BxdD_Qyv"
      },
      "outputs": [],
      "execution_count": 32
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out) # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape # Shape: (batch, num_tokens, d_in)\n",
        "        queries = self.W_query(x)\n",
        "        keys = self.W_key(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a 'num_heads' dimension\n",
        "        # Unroll last dim: (batch, num_tokens, d_out) -> (batch, num_tokens, num_tokens, head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (batch, num_tokens, num_heads, head_dim) -> (batch, num_heads, num_tokens, head_dim)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3) # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (batch, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T11:10:51.978174Z",
          "iopub.execute_input": "2025-05-30T11:10:51.978503Z",
          "iopub.status.idle": "2025-05-30T11:10:51.989156Z",
          "shell.execute_reply.started": "2025-05-30T11:10:51.978477Z",
          "shell.execute_reply": "2025-05-30T11:10:51.988075Z"
        },
        "id": "kMEaigD1_Qyv"
      },
      "outputs": [],
      "execution_count": 33
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in = cfg[\"emb_dim\"],\n",
        "            d_out = cfg[\"emb_dim\"],\n",
        "            context_length = cfg[\"context_length\"],\n",
        "            num_heads = cfg[\"n_heads\"],\n",
        "            dropout = cfg[\"drop_rate\"],\n",
        "            qkv_bias = cfg[\"qkv_bias\"]\n",
        "        )\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x) # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut # Add the original input back\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T11:11:02.354094Z",
          "iopub.execute_input": "2025-05-30T11:11:02.354390Z",
          "iopub.status.idle": "2025-05-30T11:11:02.361305Z",
          "shell.execute_reply.started": "2025-05-30T11:11:02.354369Z",
          "shell.execute_reply": "2025-05-30T11:11:02.360480Z"
        },
        "id": "yHBbo8O5_Qyv"
      },
      "outputs": [],
      "execution_count": 34
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "        )\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias = False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "\n",
        "        # The device setting will allow us to train the model on a CPU or GPU, depending on which device the input data sits on.\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device = in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T11:11:22.438988Z",
          "iopub.execute_input": "2025-05-30T11:11:22.439562Z",
          "iopub.status.idle": "2025-05-30T11:11:22.447130Z",
          "shell.execute_reply.started": "2025-05-30T11:11:22.439533Z",
          "shell.execute_reply": "2025-05-30T11:11:22.446186Z"
        },
        "id": "Fh7t7E68_Qyv"
      },
      "outputs": [],
      "execution_count": 35
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True,        # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T11:12:37.504000Z",
          "iopub.execute_input": "2025-05-30T11:12:37.504324Z",
          "iopub.status.idle": "2025-05-30T11:12:42.013678Z",
          "shell.execute_reply.started": "2025-05-30T11:12:37.504302Z",
          "shell.execute_reply": "2025-05-30T11:12:42.012717Z"
        },
        "id": "eCFskkEX_Qyv"
      },
      "outputs": [],
      "execution_count": 36
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(\n",
        "    torch.load(\n",
        "        \"gpt2-medium355M-sft.pth\",\n",
        "        map_location=torch.device(\"cpu\"),\n",
        "        weights_only=True\n",
        "    )\n",
        ")\n",
        "model.eval();"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T11:13:40.704409Z",
          "iopub.execute_input": "2025-05-30T11:13:40.704741Z",
          "iopub.status.idle": "2025-05-30T11:13:40.724849Z",
          "shell.execute_reply.started": "2025-05-30T11:13:40.704718Z",
          "shell.execute_reply": "2025-05-30T11:13:40.723433Z"
        },
        "id": "SmuL8jiR_Qyw"
      },
      "outputs": [],
      "execution_count": 37
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T11:22:13.995450Z",
          "iopub.execute_input": "2025-05-30T11:22:13.996451Z",
          "iopub.status.idle": "2025-05-30T11:22:14.004063Z",
          "shell.execute_reply.started": "2025-05-30T11:22:13.996421Z",
          "shell.execute_reply": "2025-05-30T11:22:14.002745Z"
        },
        "id": "0hBDXD2w_Qyw"
      },
      "outputs": [],
      "execution_count": 38
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # Add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T11:22:29.714095Z",
          "iopub.execute_input": "2025-05-30T11:22:29.714374Z",
          "iopub.status.idle": "2025-05-30T11:22:29.719397Z",
          "shell.execute_reply.started": "2025-05-30T11:22:29.714356Z",
          "shell.execute_reply": "2025-05-30T11:22:29.718467Z"
        },
        "id": "h5rdq8Yi_Qyw"
      },
      "outputs": [],
      "execution_count": 39
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Below is an instruction that describes a task. Write a response\n",
        "that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
        "\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-30T11:25:00.795147Z",
          "iopub.execute_input": "2025-05-30T11:25:00.795460Z",
          "iopub.status.idle": "2025-05-30T11:25:00.800786Z",
          "shell.execute_reply.started": "2025-05-30T11:25:00.795437Z",
          "shell.execute_reply": "2025-05-30T11:25:00.799683Z"
        },
        "id": "Y1DQJ6ld_Qyw"
      },
      "outputs": [],
      "execution_count": 40
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids=generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(prompt, tokenizer),\n",
        "    max_new_tokens=35,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    eos_id=50256\n",
        ")\n",
        "\n",
        "response=token_ids_to_text(token_ids, tokenizer)\n",
        "print(response)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23Gy6wgv_Qyw",
        "outputId": "30664cdb-71f8-4851-ef4e-2f7c5d558240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response\n",
            "that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
            "\n",
            "### Response:\n",
            "The meal is cooked every day by the chef.\n"
          ]
        }
      ],
      "execution_count": 41
    },
    {
      "cell_type": "markdown",
      "source": [
        "- As we can see above, the model gives a reasonable and correct response."
      ],
      "metadata": {
        "id": "yNcX16s-AUhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_response(response_text, input_text):\n",
        "    return response_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "response=extract_response(response, prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd7ZbXxqAeGS",
        "outputId": "2a1403a8-f6b5-4525-b9da-cf37bd8ac4d1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The meal is cooked every day by the chef.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- DPO works with two LLMs: a policy model (the LLM that we want to optimize) and a reference model (the original model that we keep unchanged).\n",
        "\n",
        "- In DPO, the reference model serves as a baseline or anchor, ensuring that the policy model doesn't drift too far from a reasonable behavior while optimizing for preferences."
      ],
      "metadata": {
        "id": "DF3wTCEQp6T6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "policy_model=model\n",
        "reference_model = GPTModel(BASE_CONFIG)\n",
        "reference_model.load_state_dict(\n",
        "    torch.load(\n",
        "        \"gpt2-medium355M-sft.pth\",\n",
        "        map_location=torch.device(\"cpu\"),\n",
        "        weights_only=True\n",
        "    )\n",
        ")\n",
        "reference_model.eval()\n",
        "policy_model.to(device)\n",
        "reference_model.to(device)"
      ],
      "metadata": {
        "id": "8zXs-R_4Biws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7410a7ce-9afe-4b8e-8cac-20dfa57f38a9"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 1024)\n",
              "  (pos_emb): Embedding(1024, 1024)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (12): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (13): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (14): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (15): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (16): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (17): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (18): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (19): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (20): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (21): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (22): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (23): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DPO Loss Function**\n",
        "\n",
        "Paper link: https://arxiv.org/pdf/2305.18290.pdf"
      ],
      "metadata": {
        "id": "IPLcAxBwp6HU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\mathcal{L}_{\\text{DPO}}(\\pi_\\theta; \\pi_{\\text{ref}}) = -\\mathbb{E}_{(x, y_w, y_l) \\sim \\mathcal{D}} \\left[\n",
        "\\log \\sigma \\left(\n",
        "\\beta \\log \\frac{\\pi_\\theta(y_w \\mid x)}{\\pi_{\\text{ref}}(y_w \\mid x)}\n",
        "-\n",
        "\\beta \\log \\frac{\\pi_\\theta(y_l \\mid x)}{\\pi_{\\text{ref}}(y_l \\mid x)}\n",
        "\\right)\n",
        "\\right]\n",
        "$$\n",
        "\n",
        "Let's simplify it.\n",
        "$$\n",
        "\\log\\sigma\\left(\\beta \\log \\frac{\\pi_\\theta(y_w \\mid x)}{\\pi_{\\text{ref}}(y_w \\mid x)}\n",
        "-\n",
        "\\beta \\log \\frac{\\pi_\\theta(y_l \\mid x)}{\\pi_{\\text{ref}}(y_l \\mid x)}\n",
        "\\right)\n",
        "$$\n",
        "\n",
        "\n",
        "$$\n",
        "\\log\\sigma\\beta\\left(\\log \\frac{\\pi_\\theta(y_w \\mid x)}{\\pi_{\\text{ref}}(y_w \\mid x)}\n",
        "-\n",
        "\\log \\frac{\\pi_\\theta(y_l \\mid x)}{\\pi_{\\text{ref}}(y_l \\mid x)}\n",
        "\\right)\n",
        "$$\n",
        "\n",
        "Let's apply $\\log\\left(\\frac{a}{b}\\right) = \\log a - \\log b$\n",
        "\n",
        "$$\n",
        "\\log\\sigma\\beta \\left[\n",
        "\\log \\{\\pi_\\theta(y_w \\mid x)\\} - \\log\\{\\pi_{\\text{ref}}(y_w \\mid x)\\}\n",
        "-\n",
        "\\log \\{\\pi_\\theta(y_l \\mid x)\\} + \\log\\{\\pi_{\\text{ref}}(y_l \\mid x)\\}\n",
        "\\right]\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\log\\sigma\\beta \\left(\n",
        "\\left[\n",
        "\\log \\{\\pi_\\theta(y_w \\mid x)\\} - \\log \\{\\pi_\\theta(y_l \\mid x)\\}\n",
        "\\right]\n",
        "-\n",
        "\\left[\n",
        "\\log\\{\\pi_{\\text{ref}}(y_w \\mid x)\\} - \\log\\{\\pi_{\\text{ref}}(y_l \\mid x)\\}\n",
        "\\right]\n",
        "\\right)\n",
        "$$\n",
        "\n",
        "Let's integrate mean\n",
        "\n",
        "$$\n",
        "\\mathcal{L}_{\\text{DPO}}(\\pi_\\theta; \\pi_{\\text{ref}})\n",
        "=\n",
        "-\\mathbb{E}_{(x, y_w, y_l) \\sim \\mathcal{D}} \\left[\n",
        "\\log\\sigma\\beta \\left(\n",
        "\\left[\n",
        "\\log \\{\\pi_\\theta(y_w \\mid x)\\} - \\log \\{\\pi_\\theta(y_l \\mid x)\\}\n",
        "\\right]\n",
        "-\n",
        "\\left[\n",
        "\\log\\{\\pi_{\\text{ref}}(y_w \\mid x)\\} - \\log\\{\\pi_{\\text{ref}}(y_l \\mid x)\\}\n",
        "\\right]\n",
        "\\right)\n",
        "\\right]\n",
        "$$\n",
        "\n",
        "<br>\n",
        "Where,<br>\n",
        "$\\mathcal{L}_{\\text{DPO}}$ is the DPO loss. <br>\n",
        "$\\pi_\\theta$ is the policy LLM, which will be optimize. <br>\n",
        "$\\pi_\\text{ref}$ is the reference LLM. <br>\n",
        "At the beginning of the training,  $\\pi_\\theta$  and  $\\pi_\\text{ref}$  are typically the same. <br>\n",
        "$-\\mathbb{E}_{(x, y_w, y_l) \\sim \\mathcal{D}}$ is the negative expected value with $\\mathcal{D}$ is the preference dataset. <br>\n",
        "$\\log\\sigma \\left(\\cdot\\right)$ is the logistic sigmoid function that transforms the log-odds of the preferred and rejected responses into a probability score. <br>\n",
        "$\\beta$ is the hyperparameter to control the divergence between the $\\pi_\\theta$ and $\\pi_\\text{ref}$ model. Increasing $\\beta$ increases the impact of the difference between $\\pi_\\theta$ and $\\pi_\\text{ref}$ in terms of their log probabilities on the overall loss function, therby increasing the devergence between the two model. <br>\n",
        "$y_w$ is the human preferred response. <br>\n",
        "$x$ is a prompt from the dataset. <br>\n",
        "$y_l$ is the human dispreferred response. <br>\n",
        "$\\log \\frac{\\pi_\\theta(y_w \\mid x)}{\\pi_{\\text{ref}}(y_w \\mid x)}$ is log probability of the human-preferred response that we want to maximize. <br>\n",
        "$\\log \\frac{\\pi_\\theta(y_l \\mid x)}{\\pi_{\\text{ref}}(y_l \\mid x)}$ is log probability of the human-dispreferred response that we want to minimize. <br>\n",
        "$\\log\\{\\pi_\\theta(y_w \\mid x)\\}$ is the policy chosen log probabilities. <br>\n",
        "$\\log\\{\\pi_\\theta(y_l \\mid x)\\}$ is the policy rejected log probabilities. <br>\n",
        "$\\log\\{\\pi_\\text{ref}(y_w \\mid x)\\}$ is the reference chosen log probabilities. <br>\n",
        "$\\log\\{\\pi_\\text{ref}(y_l \\mid x)\\}$ is the reference rejected log probabilities. <br>"
      ],
      "metadata": {
        "id": "3cNJSlztcA9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def compute_dpo_loss(\n",
        "      model_chosen_logprobs,\n",
        "      model_rejected_logprobs,\n",
        "      reference_chosen_logprobs,\n",
        "      reference_rejected_logprobs,\n",
        "      beta=0.1,\n",
        "    ):\n",
        "    \"\"\"Compute the DPO loss for a batch of policy and reference model log probabilities.\n",
        "\n",
        "    Args:\n",
        "        policy_chosen_logprobs: Log probabilities of the policy model for the chosen responses. Shape: (batch_size,)\n",
        "        policy_rejected_logprobs: Log probabilities of the policy model for the rejected responses. Shape: (batch_size,)\n",
        "        reference_chosen_logprobs: Log probabilities of the reference model for the chosen responses. Shape: (batch_size,)\n",
        "        reference_rejected_logprobs: Log probabilities of the reference model for the rejected responses. Shape: (batch_size,)\n",
        "        beta: Temperature parameter for the DPO loss; typically something in the range of 0.1 to 0.5. We ignore the reference model as beta -> 0.\n",
        "\n",
        "    Returns:\n",
        "        A tuple of three tensors: (loss, chosen_rewards, rejected_rewards).\n",
        "    \"\"\"\n",
        "\n",
        "    model_logratios = model_chosen_logprobs - model_rejected_logprobs\n",
        "    reference_logratios = reference_chosen_logprobs - reference_rejected_logprobs\n",
        "    logits = model_logratios - reference_logratios\n",
        "\n",
        "    losses = -F.logsigmoid(beta * logits)\n",
        "\n",
        "    # Optional values to track progress during training\n",
        "    chosen_rewards = (model_chosen_logprobs - reference_chosen_logprobs).detach()\n",
        "    rejected_rewards = (model_rejected_logprobs - reference_rejected_logprobs).detach()\n",
        "\n",
        "    # .mean() to average over the samples in the batch\n",
        "    return losses.mean(), chosen_rewards.mean(), rejected_rewards.mean()"
      ],
      "metadata": {
        "id": "BxWjoAUrstX-"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above, we assumed that the log probabilities were already computed; Let's now define a `compute_logprobs` function that we can use to compute these log probabilities that were passed into the `compute_dpo_loss` function above, that is, the values $log\\{\\pi_\\theta (y_w \\mid x)\\}$, $log\\{\\pi_\\theta (y_l \\mid x)\\}$, and so forth."
      ],
      "metadata": {
        "id": "ND1udrqsLTpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_logprobs(logits, labels, selection_mask=None):\n",
        "    \"\"\"\n",
        "    Compute log probabilities.\n",
        "\n",
        "    Args:\n",
        "      logits: Tensor of shape (batch_size, num_tokens, vocab_size)\n",
        "      labels: Tensor of shape (batch_size, num_tokens)\n",
        "      selection_mask: Tensor for shape (batch_size, num_tokens)\n",
        "\n",
        "    Returns:\n",
        "      mean_log_prob: Mean log probability excluding padding tokens.\n",
        "    \"\"\"\n",
        "\n",
        "    # Labels are the inputs shifted by one\n",
        "    labels = labels[:, 1:].clone()\n",
        "\n",
        "    # Truncate logits to match the labels num_tokens\n",
        "    logits = logits[:, :-1, :]\n",
        "\n",
        "    log_probs = F.log_softmax(logits, dim=-1)\n",
        "\n",
        "    # Gather the log probabilities for the actual labels\n",
        "    selected_log_probs = torch.gather(\n",
        "        input=log_probs,\n",
        "        dim=-1,\n",
        "        index=labels.unsqueeze(-1)\n",
        "    ).squeeze(-1)\n",
        "\n",
        "    if selection_mask is not None:\n",
        "        mask = selection_mask[:, 1:].clone()\n",
        "\n",
        "        # Apply the mask to filter out padding tokens\n",
        "        selected_log_probs = selected_log_probs * mask\n",
        "\n",
        "        # Calculate the average log probability excluding padding tokens\n",
        "        # This averages over the tokens, so the shape is (batch_size,)\n",
        "        avg_log_prob = selected_log_probs.sum(-1) / mask.sum(-1)\n",
        "\n",
        "        return avg_log_prob\n",
        "\n",
        "    else:\n",
        "        return selected_log_probs.mean(-1)"
      ],
      "metadata": {
        "id": "h7zPKuPoMcXS"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Note that this function above might look a bit intimidating at first due to the `torch.gather` function, but it's pretty similar to what happens under the hood in PyTorch's `cross_entropy` function.\n",
        "\n",
        "- For example, consider the following example."
      ],
      "metadata": {
        "id": "7jNivHFXQzNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "\n",
        "logits = torch.tensor( # Shape: (2, 3)\n",
        "    [[2.0, 1.0, 0.1],\n",
        "     [0.5, 2.5, 0.3]]\n",
        ")\n",
        "targets = torch.tensor([0, 2]) # Shape: (2, )\n",
        "\n",
        "# Manual loss using torch.gather\n",
        "log_softmax_logits = F.log_softmax(logits, dim=1) # Shape: (2, 3)\n",
        "selected_log_probs = torch.gather(\n",
        "    input=log_softmax_logits,\n",
        "    dim=1,\n",
        "    index=targets.unsqueeze(dim=1), # Shape: (2, 1)\n",
        ").squeeze(dim=1) # Shape: (2, )\n",
        "manual_loss = -selected_log_probs.mean() # Averaging over the batch\n",
        "\n",
        "# PyTorch loss\n",
        "cross_entropy_loss = F.cross_entropy(logits, targets)\n",
        "print(manual_loss, cross_entropy_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITRjdtRsRIi2",
        "outputId": "8b6e9219-24a2-4096-f5a5-a0857ad457a7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.4185) tensor(1.4185)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- So, above, we can see that the two implementations are equivalent, but let's narrow down a bit further to the `torch.gather` mechanics.\n",
        "- Consider the following two tensors."
      ],
      "metadata": {
        "id": "H2D5MFKJUTwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor(\n",
        "    [[1.0, 2.0],\n",
        "     [3.0, 4.0]]\n",
        ")\n",
        "\n",
        "m = torch.tensor(\n",
        "    [[1, 1], # For row 0, we will pick column 1 (twice)\n",
        "     [0, 1]] # For row 1, we will pick column 0 and column 1\n",
        ")"
      ],
      "metadata": {
        "id": "3b0Ku-F3UoLK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Above, `t` is a tensor we want to select from, and `m` is a mask to specify how we want to select.\n",
        "  - For instance, since `m` contains `[1, 1]` in the first row, it will select column one of first row twice of `t`.\n",
        "  - The second row of `m`, `[0, 1]`, selects column 0 and column 1 of second row of `t`."
      ],
      "metadata": {
        "id": "FnuzbE8QVpHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.gather(\n",
        "    input=t,\n",
        "    dim=-1,\n",
        "    index=m\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEHfjBW_Y8VB",
        "outputId": "caf8a3f0-535e-491e-f863-6678a4eaa4f8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2.],\n",
              "        [3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In other words, `torch.gather` is a selection function.\n",
        "- When we computed the loss earlier, we used it to retrieve the log probabilities corresponding to the correct token in the 50,256 vocabulary.\n",
        "- The `correct` tokens are the tokens given in the response entry.\n",
        "- Regarding the `compute_logprobs` function above, we use `torch.gather` here because it gives us a bit more control than `cross_entropy`, but is, in essence, a similar idea.\n",
        "- The `selection_mask` we use there is to optionally ignore prompt and padding tokens.\n",
        "- We can then use the `compute_logprobs` function as follows to compute the inputs for the `compute_dpo_loss` function."
      ],
      "metadata": {
        "id": "AnMKWGsWZaZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_dpo_loss_batch(batch, policy_model, reference_model, beta):\n",
        "    \"\"\"Compute the DPO loss on an input batch\"\"\"\n",
        "\n",
        "    # where policy_model(batch[\"chosen\"]) are the logits\n",
        "    policy_chosen_log_probas = compute_logprobs(\n",
        "        logits=policy_model(batch[\"chosen\"]),\n",
        "        labels=batch[\"chosen\"],\n",
        "        selection_mask=batch[\"chosen_mask\"]\n",
        "    )\n",
        "    policy_rejected_log_probas = compute_logprobs(\n",
        "        logits=policy_model(batch[\"rejected\"]),\n",
        "        labels=batch[\"rejected\"],\n",
        "        selection_mask=batch[\"rejected_mask\"]\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        ref_chosen_log_probas = compute_logprobs(\n",
        "            logits=reference_model(batch[\"chosen\"]),\n",
        "            labels=batch[\"chosen\"],\n",
        "            selection_mask=batch[\"chosen_mask\"]\n",
        "        )\n",
        "        ref_rejected_log_probas = compute_logprobs(\n",
        "            logits=reference_model(batch[\"rejected\"]),\n",
        "            labels=batch[\"rejected\"],\n",
        "            selection_mask=batch[\"rejected_mask\"]\n",
        "        )\n",
        "    loss, chosen_rewards, rejected_rewards = compute_dpo_loss(\n",
        "        model_chosen_logprobs=policy_chosen_log_probas,\n",
        "        model_rejected_logprobs=policy_rejected_log_probas,\n",
        "        reference_chosen_logprobs=ref_chosen_log_probas,\n",
        "        reference_rejected_logprobs=ref_rejected_log_probas,\n",
        "        beta=beta\n",
        "    )\n",
        "    return loss, chosen_rewards, rejected_rewards"
      ],
      "metadata": {
        "id": "qGnt95o9a1cg"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above function works for a single batch. Below, we extend this function to work for a specified `num_batches` in a dataloader."
      ],
      "metadata": {
        "id": "BkDW4vzhdPdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_dpo_loss_loader(\n",
        "    data_loader,\n",
        "    policy_model,\n",
        "    reference_model,\n",
        "    beta,\n",
        "    num_batches=None\n",
        "):\n",
        "    \"\"\"Apply compute_dpo_loss_batch to a whole dataloader\"\"\"\n",
        "    total_loss = 0.0\n",
        "    total_chosen_rewards = 0.0\n",
        "    total_rejected_rewards = 0.0\n",
        "\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, batch in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss, chosen_rewards, rejected_rewards = compute_dpo_loss_batch(\n",
        "                batch=batch,\n",
        "                policy_model=policy_model,\n",
        "                reference_model=reference_model,\n",
        "                beta=beta\n",
        "            )\n",
        "            total_loss += loss.item()\n",
        "            total_chosen_rewards += chosen_rewards.item()\n",
        "            total_rejected_rewards += rejected_rewards.item()\n",
        "\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # calculate average\n",
        "    total_loss /= num_batches\n",
        "    total_chosen_rewards /= num_batches\n",
        "    total_rejected_rewards /= num_batches\n",
        "    return total_loss, total_chosen_rewards, total_rejected_rewards"
      ],
      "metadata": {
        "id": "nGocClEAdZ_T"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Why a specified `num_batches`? That's purely for efficiency reasons (because calculating the loss on the whole dataset each time would slow down the training significantly).\n",
        "\n",
        "- Lastly, we define a convenience function for our training function later; this evaluate `compute_dpo_loss_loader` function computes the DPO loss and rewards for both the training and validation loader for logging purposes."
      ],
      "metadata": {
        "id": "BsCao8K2fdi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_dpo_loss_loader(policy_model, reference_model, train_loader, val_loader, beta, eval_iter):\n",
        "    \"\"\"Compute the DPO loss for the training and validation dataset\"\"\"\n",
        "\n",
        "    policy_model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss, train_chosen_rewards, train_rejected_rewards = compute_dpo_loss_loader(\n",
        "            data_loader=train_loader,\n",
        "            policy_model=policy_model,\n",
        "            reference_model=reference_model,\n",
        "            beta=beta,\n",
        "            num_batches=eval_iter\n",
        "        )\n",
        "\n",
        "        val_loss, val_chosen_rewards, val_rejected_rewards = compute_dpo_loss_loader(\n",
        "            data_loader=val_loader,\n",
        "            policy_model=policy_model,\n",
        "            reference_model=reference_model,\n",
        "            beta=beta,\n",
        "            num_batches=eval_iter\n",
        "        )\n",
        "\n",
        "    result = {\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_chosen_reward\": train_chosen_rewards,\n",
        "        \"train_rejected_reward\": train_rejected_rewards,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"val_chosen_reward\": val_chosen_rewards,\n",
        "        \"val_rejected_reward\": val_rejected_rewards\n",
        "    }\n",
        "\n",
        "    policy_model.train()\n",
        "    return result"
      ],
      "metadata": {
        "id": "T2lFIeY_gdFQ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Before we start the training, let's print the initial losses and rewards."
      ],
      "metadata": {
        "id": "I35OHPh4r9JW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "result = evaluate_dpo_loss_loader(\n",
        "    policy_model=policy_model,\n",
        "    reference_model=reference_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    beta=0.1,\n",
        "    eval_iter=5\n",
        ")\n",
        "\n",
        "print(\"Training loss:\", result[\"train_loss\"])\n",
        "print(\"Validation loss:\", result[\"val_loss\"])\n",
        "\n",
        "print(\"Train reward margin:\", result[\"train_chosen_reward\"] - result[\"train_rejected_reward\"])\n",
        "print(\"Val reward margin:\", result[\"val_chosen_reward\"] - result[\"val_rejected_reward\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LshaeQCvoQ1Y",
        "outputId": "50765196-8913-4deb-86dc-11b4ae6855f2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.6931471824645996\n",
            "Validation loss: 0.6931471824645996\n",
            "Train reward margin: 0.0\n",
            "Val reward margin: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Also, let's take a look at some of the initial model_responses (the first 3 examples in the validation set)."
      ],
      "metadata": {
        "id": "jRgKvdk8osPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "\n",
        "for entry in val_data[:3]:\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        ")\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"\\n-------------------------------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pcfg2ds4o2es",
        "outputId": "20122c81-8856-429a-acb9-d3ada127d7f4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
            "\n",
            "Correct response:\n",
            ">> The meal is cooked by the chef every day.\n",
            "\n",
            "Model response:\n",
            ">> The meal is cooked every day by the chef.\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Classify an input string as either a noun or a verb.\n",
            "\n",
            "### Input:\n",
            "Dance\n",
            "\n",
            "Correct response:\n",
            ">> 'Dance' can be classified as a verb.\n",
            "\n",
            "Model response:\n",
            ">> Dance is a verb.\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a metaphor.\n",
            "\n",
            "### Input:\n",
            "The book is very interesting.\n",
            "\n",
            "Correct response:\n",
            ">> The book is a page-turner.\n",
            "\n",
            "Model response:\n",
            ">> The book is like a treasure.\n",
            "\n",
            "-------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Above, we see the original model responses.\n",
        "- Note that the goal of DPO is to induce slight style changes. This means we want the model to generate similar but slightly more polite responses."
      ],
      "metadata": {
        "id": "4nN4KwAQS1N8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training the model**\n",
        "\n",
        "- After setting up the DPO loss functions in the previous section, we can now finally train the model.\n",
        "- Note that this training function is the same one we used for pretraining and instruction finetuning, with minor differences:\n",
        "  - We swap the cross-entropy loss with our new DPO loss function.\n",
        "  - We also track the rewards and reward margins, which are comonly used in RLHF and DPO contexts to track the training progress.\n"
      ],
      "metadata": {
        "id": "3GTwzeDBiHXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (batch, n_tokens) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model,\n",
        "            idx=encoded,\n",
        "            max_new_tokens=50,\n",
        "            context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "bJqiVY8iiKgj"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_dpo_simple(\n",
        "    policy_model,\n",
        "    reference_model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer,\n",
        "    num_epochs,\n",
        "    beta,\n",
        "    eval_freq,\n",
        "    eval_iter,\n",
        "    start_context,\n",
        "    tokenizer\n",
        "):\n",
        "    tracking = {\n",
        "        \"train_losses\": [],\n",
        "        \"train_chosen_rewards\": [],\n",
        "        \"train_rejected_rewards\": [],\n",
        "        \"val_losses\": [],\n",
        "        \"val_chosen_rewards\": [],\n",
        "        \"val_rejected_rewards\": [],\n",
        "        \"tokens_seen\": []\n",
        "    }\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        policy_model.train()  # Set model to training mode\n",
        "\n",
        "        for batch in train_loader:\n",
        "\n",
        "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
        "\n",
        "            loss, chosen_rewards, rejected_rewards = compute_dpo_loss_batch(\n",
        "                batch=batch,\n",
        "                policy_model=policy_model,\n",
        "                reference_model=reference_model,\n",
        "                beta=beta\n",
        "            )\n",
        "\n",
        "            loss.backward()  # Calculate loss gradients\n",
        "            optimizer.step()  # Update model weights using loss gradients\n",
        "\n",
        "            tokens_seen += batch[\"chosen\"].numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                res = evaluate_dpo_loss_loader(\n",
        "                    policy_model=policy_model,\n",
        "                    reference_model=reference_model,\n",
        "                    train_loader=train_loader,\n",
        "                    val_loader=val_loader,\n",
        "                    beta=beta,\n",
        "                    eval_iter=eval_iter\n",
        "                )\n",
        "                tracking[\"train_losses\"].append(res[\"train_loss\"])\n",
        "                tracking[\"train_chosen_rewards\"].append(res[\"train_chosen_reward\"])\n",
        "                tracking[\"train_rejected_rewards\"].append(res[\"train_rejected_reward\"])\n",
        "                tracking[\"val_losses\"].append(res[\"val_loss\"])\n",
        "                tracking[\"val_chosen_rewards\"].append(res[\"val_chosen_reward\"])\n",
        "                tracking[\"val_rejected_rewards\"].append(res[\"val_rejected_reward\"])\n",
        "                tracking[\"tokens_seen\"].append(tokens_seen)\n",
        "                train_reward_margin = res[\"train_chosen_reward\"] - res[\"train_rejected_reward\"]\n",
        "                val_reward_margin = res[\"val_chosen_reward\"] - res[\"val_rejected_reward\"]\n",
        "\n",
        "                print(\n",
        "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                    f\"Train loss {res['train_loss']:.3f}, Val loss {res['val_loss']:.3f}, \"\n",
        "                    f\"Train reward margins {train_reward_margin:.3f}, \"\n",
        "                    f\"Val reward margins {val_reward_margin:.3f}\"\n",
        "                )\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            device=loss.device,\n",
        "            start_context=start_context\n",
        "        )\n",
        "\n",
        "    return tracking"
      ],
      "metadata": {
        "id": "ddAbbhP-kDM2"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Before we execute the following code cell that starts the training, here are a few notes about some of the settings:\n",
        "  - We are only passing the parameters of the `policy model` into the `AdamW` optimizer; that's the model we want to optimize (we don't want to modify the `reference model`).\n",
        "  - We only train for 1 epoch; that's because DPO is very prone to collapse (the loss might improve, but the model will start generating nonsensical texts).\n",
        "  - In DPO, it's best to use a very small learning rate.\n",
        "  - The beta value can be increased from 0.1 to 0.5 to reduce the effect of DPO (we use 0.1 here to make the results more noticeable)."
      ],
      "metadata": {
        "id": "J39nrCnNoDBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(policy_model.parameters(), lr=5e-6, weight_decay=0.01)\n",
        "\n",
        "num_epochs = 1\n",
        "tracking = train_model_dpo_simple(\n",
        "    policy_model=policy_model,\n",
        "    reference_model=reference_model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=num_epochs,\n",
        "    beta=0.1, # value between 0.1 and 0.5\n",
        "    eval_freq=5,\n",
        "    eval_iter=5,\n",
        "    start_context=format_input(val_data[2]),\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZHd7k6RWZjD",
        "outputId": "3d4c3eb1-afce-4c9b-a875-2cc5c6c1990a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 0.692, Val loss 0.693, Train reward margins 0.013, Val reward margins 0.006\n",
            "Ep 1 (Step 000005): Train loss 0.691, Val loss 0.692, Train reward margins 0.046, Val reward margins 0.031\n",
            "Ep 1 (Step 000010): Train loss 0.687, Val loss 0.690, Train reward margins 0.118, Val reward margins 0.058\n",
            "Ep 1 (Step 000015): Train loss 0.681, Val loss 0.688, Train reward margins 0.245, Val reward margins 0.100\n",
            "Ep 1 (Step 000020): Train loss 0.681, Val loss 0.685, Train reward margins 0.255, Val reward margins 0.163\n",
            "Ep 1 (Step 000025): Train loss 0.672, Val loss 0.681, Train reward margins 0.435, Val reward margins 0.253\n",
            "Ep 1 (Step 000030): Train loss 0.676, Val loss 0.675, Train reward margins 0.362, Val reward margins 0.375\n",
            "Ep 1 (Step 000035): Train loss 0.668, Val loss 0.671, Train reward margins 0.542, Val reward margins 0.460\n",
            "Ep 1 (Step 000040): Train loss 0.674, Val loss 0.668, Train reward margins 0.422, Val reward margins 0.542\n",
            "Ep 1 (Step 000045): Train loss 0.651, Val loss 0.661, Train reward margins 0.924, Val reward margins 0.689\n",
            "Ep 1 (Step 000050): Train loss 0.659, Val loss 0.656, Train reward margins 0.773, Val reward margins 0.819\n",
            "Ep 1 (Step 000055): Train loss 0.644, Val loss 0.652, Train reward margins 1.088, Val reward margins 0.909\n",
            "Ep 1 (Step 000060): Train loss 0.654, Val loss 0.648, Train reward margins 0.882, Val reward margins 1.001\n",
            "Ep 1 (Step 000065): Train loss 0.627, Val loss 0.645, Train reward margins 1.489, Val reward margins 1.085\n",
            "Ep 1 (Step 000070): Train loss 0.614, Val loss 0.640, Train reward margins 1.823, Val reward margins 1.187\n",
            "Ep 1 (Step 000075): Train loss 0.611, Val loss 0.637, Train reward margins 1.917, Val reward margins 1.276\n",
            "Ep 1 (Step 000080): Train loss 0.584, Val loss 0.634, Train reward margins 2.569, Val reward margins 1.353\n",
            "Ep 1 (Step 000085): Train loss 0.606, Val loss 0.630, Train reward margins 2.039, Val reward margins 1.448\n",
            "Ep 1 (Step 000090): Train loss 0.647, Val loss 0.626, Train reward margins 1.063, Val reward margins 1.537\n",
            "Ep 1 (Step 000095): Train loss 0.594, Val loss 0.624, Train reward margins 2.310, Val reward margins 1.599\n",
            "Ep 1 (Step 000100): Train loss 0.587, Val loss 0.621, Train reward margins 2.503, Val reward margins 1.667\n",
            "Ep 1 (Step 000105): Train loss 0.574, Val loss 0.619, Train reward margins 2.909, Val reward margins 1.727\n",
            "Ep 1 (Step 000110): Train loss 0.597, Val loss 0.616, Train reward margins 2.278, Val reward margins 1.818\n",
            "Ep 1 (Step 000115): Train loss 0.606, Val loss 0.612, Train reward margins 1.998, Val reward margins 1.899\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Rewrite the sentence using a metaphor.  ### Input: The book is very interesting.  ### Response: The book is interesting.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom?  ### Response\n",
            "Training completed in 5.84 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Analyzing the results**\n",
        "\n",
        "- Let's begin analyzing the results by plotting the DPO loss."
      ],
      "metadata": {
        "id": "L8rTAG4CXqS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    #plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "z7Av3zl1XvRg"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(tracking[\"train_losses\"]))\n",
        "\n",
        "plot_losses(\n",
        "    epochs_seen=epochs_tensor,\n",
        "    tokens_seen=tracking[\"tokens_seen\"],\n",
        "    train_losses=tracking[\"train_losses\"],\n",
        "    val_losses=tracking[\"val_losses\"],\n",
        "    # label=\"loss\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "iCd0aPFAX-Yq",
        "outputId": "a642cf33-3190-47f1-81a4-ca5389c49af4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- As we can see above, the loss continues to improve, which is a good sign.\n",
        "- Based on the downward slope, one might be tempted to train the model a bit further (and readers are encouraged to try this), but note that DPO is prone to collapse, where the model may start generating nonsensical responses."
      ],
      "metadata": {
        "id": "pxlvubjRcV_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Next, let's take a look at the reward margins."
      ],
      "metadata": {
        "id": "QOJfBa-acstl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_reward_margins = [i-j for i,j in zip(tracking[\"train_chosen_rewards\"], tracking[\"train_rejected_rewards\"])]\n",
        "val_reward_margins = [i-j for i,j in zip(tracking[\"val_chosen_rewards\"], tracking[\"val_rejected_rewards\"])]\n",
        "\n",
        "plot_losses(\n",
        "    epochs_seen=epochs_tensor,\n",
        "    tokens_seen=tracking[\"tokens_seen\"],\n",
        "    train_losses=train_reward_margins,\n",
        "    val_losses=val_reward_margins,\n",
        "    # label=\"reward margins\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "yPFFX8bCY0GG",
        "outputId": "616aff7f-9c73-4bbb-de0c-efaf3fc15a8d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- As we can see, and as it's desired, the reward margins improve, this mirrors the loss curve and is a good sign.\n",
        "- Note that DPO losses and reward margins are valuable metrics to track during training; however, they don't tell the whole story."
      ],
      "metadata": {
        "id": "eMSSihvpczBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lastly, and most importly, we have to conduct a qualitative check of the responses.\n",
        "- Here, we will look at the response."
      ],
      "metadata": {
        "id": "H2APgxFsdmBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "for entry in val_data[:3]:\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=reference_model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text=token_ids_to_text(token_ids, tokenizer)\n",
        "    reference_response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=policy_model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text=token_ids_to_text(token_ids, tokenizer)\n",
        "    policy_response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nReference model response:\\n>> {reference_response_text.strip()}\")\n",
        "    print(f\"\\nPolicy model response:\\n>> {policy_response_text.strip()}\")\n",
        "    print(\"\\n----------------------------------------------------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N69eNJKtdyUs",
        "outputId": "c3526276-e04a-4c9c-c21d-b613916e7c18"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
            "\n",
            "Correct response:\n",
            ">> The meal is cooked by the chef every day.\n",
            "\n",
            "Reference model response:\n",
            ">> The meal is cooked every day by the chef.\n",
            "\n",
            "Policy model response:\n",
            ">> The meal was prepared by the chef.\n",
            "\n",
            "----------------------------------------------------------\n",
            "\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Classify an input string as either a noun or a verb.\n",
            "\n",
            "### Input:\n",
            "Dance\n",
            "\n",
            "Correct response:\n",
            ">> 'Dance' can be classified as a verb.\n",
            "\n",
            "Reference model response:\n",
            ">> Dance is a verb.\n",
            "\n",
            "Policy model response:\n",
            ">> The input 'Dance' could be classified as a verb.\n",
            "\n",
            "----------------------------------------------------------\n",
            "\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a metaphor.\n",
            "\n",
            "### Input:\n",
            "The book is very interesting.\n",
            "\n",
            "Correct response:\n",
            ">> The book is a page-turner.\n",
            "\n",
            "Reference model response:\n",
            ">> The book is like a treasure.\n",
            "\n",
            "Policy model response:\n",
            ">> The book is interesting.\n",
            "\n",
            "----------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "\n",
        "for entry in test_data[:3]:\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=reference_model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    reference_response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=policy_model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    policy_response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nReference model response:\\n>> {reference_response_text.strip()}\")\n",
        "    print(f\"\\nPolicy model response:\\n>> {policy_response_text.strip()}\")\n",
        "    print(\"\\n-------------------------------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBLAA3yLmYuT",
        "outputId": "73ec12d3-29c9-4a73-d8ed-7a367ee9838c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n",
            "\n",
            "Correct response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Reference model response:\n",
            ">> The car is as fast as a bullet.\n",
            "\n",
            "Policy model response:\n",
            ">> The car was as fast as an elephant.\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What type of cloud is typically associated with thunderstorms?\n",
            "\n",
            "Correct response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Reference model response:\n",
            ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
            "\n",
            "Policy model response:\n",
            ">> The type of cloud typically associated with thunderstorms is a cumulus.\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Name the author of 'Pride and Prejudice'.\n",
            "\n",
            "Correct response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Reference model response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "\n",
            "Policy model response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "\n",
            "-------------------------------------\n",
            "\n"
          ]
        }
      ]
    }
  ]
}